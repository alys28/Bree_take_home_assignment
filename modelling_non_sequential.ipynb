{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('preprocessed_data/200_data_pts_features.npy')\n",
    "y = np.load('preprocessed_data/200_data_pts_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      " [[ 1.50000000e+01  1.90000000e-01  2.00000000e+01 ...  3.38000000e+02\n",
      "  -2.49944000e+03  3.62855000e+03]\n",
      " [ 1.90000000e+02  9.30000000e-01  1.80000000e+02 ...  2.00000000e+00\n",
      "  -1.60100000e+01  2.88990000e+02]\n",
      " [ 3.10000000e+02 -2.19500000e+01  2.64722222e+02 ...  4.60000000e+01\n",
      "  -3.69310000e+02  7.57605000e+03]\n",
      " ...\n",
      " [ 2.50000000e+02  2.39780000e+02  2.50000000e+02 ...  4.90000000e+02\n",
      "  -2.06368000e+03  2.22557000e+03]\n",
      " [ 2.50000000e+02 -8.23000000e+00  2.50000000e+02 ...  4.24000000e+02\n",
      "  -5.74431000e+03  2.74332000e+03]\n",
      " [ 3.20000000e+02  2.97133000e+03  1.93529412e+02 ...  4.80000000e+01\n",
      "  -3.36420000e+02  2.97133000e+03]]\n",
      "y_train:\n",
      " [ 1220.7    125.14    62.83 ...  1292.35 -1632.6   1135.66]\n",
      "X_test:\n",
      " [[ 3.50000000e+02  1.00920000e+02  2.64473684e+02 ...  1.98200000e+03\n",
      "  -2.52180000e+03  2.79110000e+03]\n",
      " [ 1.70000000e+02  1.28067000e+03  1.00833333e+02 ...  2.10000000e+01\n",
      "  -2.39600000e+01  2.47625000e+03]\n",
      " [ 2.50000000e+02  1.00000000e+01  2.16875000e+02 ...  1.34100000e+03\n",
      "  -2.52180000e+03  2.62180000e+03]\n",
      " ...\n",
      " [ 8.00000000e+01  0.00000000e+00  5.00000000e+01 ...  3.00000000e+00\n",
      "  -3.11570000e+02  1.66778000e+03]\n",
      " [ 2.50000000e+02  9.34020000e+02  2.50000000e+02 ...  7.66000000e+02\n",
      "  -1.93971000e+03  3.44700000e+03]\n",
      " [ 1.50000000e+02  0.00000000e+00  1.95000000e+02 ...  9.12000000e+02\n",
      "  -1.80632000e+03  9.28040000e+02]]\n",
      "y_test:\n",
      " [ 5.62810e+02  1.44151e+03 -1.10399e+03  1.28986e+03  2.15521e+03\n",
      "  9.29320e+02  5.16750e+02 -1.77000e+00  1.79407e+03  1.18888e+03\n",
      "  1.86051e+03  7.38040e+02  2.59770e+02  1.24984e+03  1.00871e+03\n",
      "  6.50000e+00  5.85270e+02  2.22717e+03  8.24220e+02 -9.07990e+02\n",
      "  2.13510e+02  3.11500e+01  1.61790e+02  9.32990e+02  1.40026e+03\n",
      "  2.45135e+03  4.62930e+02  2.31770e+02 -2.54670e+02  7.61290e+02\n",
      "  3.12000e+01  8.92890e+02  1.75942e+03  1.50292e+03  2.27563e+03\n",
      "  1.07298e+03 -1.02301e+03  2.17091e+03  9.36040e+02  1.44127e+03\n",
      "  4.51900e+01  1.38533e+03  9.44680e+02  5.88950e+02 -2.54490e+02\n",
      "  1.30915e+03  1.44470e+03  1.48495e+03  6.73800e+01  2.37612e+03\n",
      "  5.86820e+02  2.26359e+03  1.93641e+03  6.67570e+02  1.41954e+03\n",
      "  4.99260e+02  2.78050e+02  1.47229e+03  8.35550e+02 -2.18990e+02\n",
      "  1.42979e+03  1.36809e+03  1.45314e+03  1.78940e+03  8.99030e+02\n",
      "  1.73011e+03  7.70950e+02 -2.65490e+02  7.18180e+02  1.86265e+03\n",
      "  8.95260e+02  7.62380e+02  1.50283e+03  2.02470e+02  5.73570e+02\n",
      "  1.08684e+03  6.90410e+02  1.84740e+02 -8.71800e+01  8.70940e+02\n",
      "  5.06620e+02  6.02000e+00  7.45910e+02  1.26500e+01  1.88190e+02\n",
      "  1.51724e+03  1.26620e+03  1.17529e+03  9.37010e+02  1.18677e+03\n",
      "  5.95960e+02  9.63990e+02  2.63192e+03  3.15929e+03  1.49214e+03\n",
      "  1.84632e+03  1.71851e+03  1.09010e+03  7.12110e+02  1.54969e+03\n",
      "  1.41705e+03  2.46468e+03  9.90680e+02  1.85940e+03  1.77807e+03\n",
      "  5.82020e+02 -7.38990e+02  2.15318e+03 -2.51030e+02  9.05540e+02\n",
      "  1.53086e+03  1.47325e+03  5.23020e+02 -2.63130e+02  2.64700e+02\n",
      "  5.33700e+02  1.93425e+03  2.77090e+02 -1.19407e+03  1.13107e+03\n",
      " -4.04560e+02  6.46740e+02  2.54480e+03  1.60996e+03  8.43520e+02\n",
      "  2.73750e+02 -1.51934e+03 -2.64930e+02  3.06160e+02 -2.18220e+02\n",
      "  1.16167e+03  1.35409e+03  1.11459e+03  1.13447e+03  1.24259e+03\n",
      " -1.02899e+03  1.18943e+03 -2.49440e+02  7.96050e+02  7.87248e+03\n",
      "  1.57116e+03 -2.50680e+02 -2.75430e+02  2.00440e+02  8.68000e+00\n",
      "  4.13140e+02  5.47030e+02  4.16930e+02  2.84750e+02  9.10320e+02\n",
      "  9.11020e+02 -1.36629e+03  2.11146e+03  1.26474e+03  6.06000e+00\n",
      "  1.03576e+03 -7.43200e+01  1.30555e+03  2.75111e+03  8.00370e+02\n",
      "  2.34005e+03  9.57360e+02  2.30158e+03  1.56391e+03  1.21359e+03\n",
      "  4.60850e+02 -5.22400e+01  3.33500e+01  1.01674e+03 -8.96900e+01\n",
      "  1.01944e+03  1.34049e+03  8.86190e+02 -5.28540e+02  2.17552e+03\n",
      "  4.46920e+02  2.06344e+03  3.04530e+02  2.10800e+02  3.51287e+03\n",
      "  1.99392e+03  7.40590e+02  1.00472e+03 -9.50940e+02  5.92120e+02\n",
      "  7.62170e+02  4.84370e+02  8.59860e+02  8.32200e+02  1.37661e+03\n",
      "  8.00320e+02  5.30210e+02  3.72700e+03  3.46460e+02  1.26201e+03\n",
      "  1.49199e+03  1.21283e+03  1.07702e+03  4.08880e+02  1.30201e+03\n",
      "  1.36566e+03  1.26195e+03  4.44100e+01  1.09117e+03 -4.44000e+02\n",
      "  2.14779e+03  1.63000e+01  1.27289e+03  1.03388e+03  7.55380e+02\n",
      " -1.64530e+02 -2.65110e+02  3.62320e+02  1.34953e+03  1.20780e+02\n",
      "  1.47858e+03 -1.80538e+03  9.77010e+02  2.33040e+02  1.64843e+03\n",
      "  6.86170e+02  7.31830e+02  7.65300e+02  2.63996e+03  7.63830e+02\n",
      "  9.31400e+02  1.13638e+03  3.93000e+02  9.05450e+02  5.05490e+02\n",
      "  1.63892e+03 -2.96770e+02  2.41100e+02  7.47720e+02 -2.19140e+02\n",
      "  8.67000e+02  6.63680e+02  1.27060e+02  1.10076e+03  1.05011e+03\n",
      "  1.73405e+03  3.91930e+02  3.63000e+00  8.36230e+02  1.50800e+02\n",
      "  3.68810e+02  2.66840e+02  5.93200e+01  7.74620e+02  1.00717e+03\n",
      "  2.22362e+03  1.49630e+03  3.96920e+02  7.31420e+02 -3.09780e+02\n",
      " -4.76990e+02  7.06200e+01  6.59330e+02 -1.70240e+02  1.17592e+03\n",
      "  6.34530e+02  1.22196e+03  1.38126e+03  7.20370e+02  9.11870e+02\n",
      "  2.54871e+03  1.45668e+03  1.00748e+03  9.85890e+02 -9.56900e+01\n",
      "  2.97010e+02  9.65470e+02  5.42520e+02  1.80680e+02  4.61030e+02\n",
      "  6.58980e+02  5.41900e+01  4.69080e+02  1.41001e+03  4.54690e+02\n",
      " -2.73990e+02  1.43221e+03  2.07772e+03 -4.40900e+02  2.52524e+03\n",
      "  9.04070e+02  6.65340e+02  2.16125e+03  4.06010e+02  6.73270e+02\n",
      "  1.39825e+03  1.11198e+03  8.02000e+00  1.44058e+03  5.43780e+02\n",
      "  8.57850e+02  8.77270e+02  1.15362e+03  1.06682e+03  2.46430e+02\n",
      "  3.71190e+02  7.26810e+02 -2.78640e+02  4.43640e+02  9.86130e+02\n",
      " -4.32800e+02  1.49821e+03  9.27210e+02  1.48690e+03 -6.42150e+02\n",
      "  5.10880e+02  2.42050e+03  1.15337e+03  1.22103e+03 -6.71610e+02\n",
      "  1.32523e+03  3.60000e-01  9.20040e+02  1.36762e+03  8.01010e+02\n",
      "  9.09990e+02  1.65584e+03  1.22729e+03  1.69789e+03 -3.00220e+02\n",
      "  2.25714e+03  3.54640e+02  9.35300e+02  1.12932e+03 -2.28110e+02\n",
      "  7.57370e+02  4.20920e+02  7.51000e+00  6.99120e+02  2.69077e+03\n",
      "  7.41710e+02  6.41490e+02  7.04160e+02  2.20020e+02  6.56580e+02\n",
      "  1.57625e+03  1.38740e+02  4.25320e+02  1.03270e+02  7.99980e+02\n",
      " -2.10960e+02  6.34700e+01 -2.82330e+02  1.08740e+03 -2.12160e+02\n",
      "  1.00423e+03  1.38441e+03  1.49527e+03  1.09259e+03  3.66173e+03\n",
      "  7.52890e+02  2.72500e+03  6.02200e+01  1.58077e+03  7.02540e+02\n",
      "  1.13826e+03  1.83740e+02  1.76937e+03  1.69734e+03  1.49825e+03\n",
      "  4.59290e+02 -4.30950e+02  3.20420e+02  1.77796e+03  4.02260e+02\n",
      "  7.24680e+02 -1.18000e+01  5.56880e+02 -9.83000e+02  6.95590e+02\n",
      "  1.22596e+03  1.38894e+03  6.34920e+02  2.48368e+03 -2.54010e+02\n",
      "  5.06200e+02  9.80630e+02  1.02571e+03  1.80068e+03  6.63510e+02\n",
      "  1.18077e+03  5.81730e+02  2.24340e+02  2.13942e+03  7.49010e+02\n",
      "  1.08863e+03 -1.24838e+03 -4.25610e+02  1.80051e+03  2.79050e+02\n",
      "  1.00540e+02  4.69550e+02  1.78342e+03  1.65175e+03  5.42480e+02\n",
      "  4.96000e+00  1.11195e+03  8.93860e+02  1.27146e+03  8.18960e+02\n",
      "  9.98990e+02  6.46980e+02  1.08340e+03 -4.38270e+02  7.60570e+02\n",
      "  6.05180e+02  1.41338e+03  9.56419e+03  1.27988e+03  7.99040e+02\n",
      "  1.04890e+03  1.22102e+03  2.49610e+02  6.81360e+02  1.03040e+02\n",
      "  1.02326e+03  4.90480e+02  1.07056e+03  9.15450e+02  1.73879e+03\n",
      "  1.42586e+03  6.25450e+02  1.67820e+02 -1.13020e+02  2.57406e+03\n",
      "  1.12458e+03  1.70901e+03  3.20460e+02  1.20224e+03 -9.32600e+01\n",
      "  1.41140e+03  1.30759e+03 -2.47580e+02  1.77910e+03  6.77040e+02\n",
      " -1.71190e+02  7.71010e+02  1.03240e+02  7.85670e+02  7.48990e+02\n",
      "  8.15940e+02  7.39460e+02  5.84920e+02 -2.24030e+02  6.82400e+02\n",
      "  3.40000e-01  1.71503e+03  1.37929e+03  2.56059e+03  4.47010e+02\n",
      "  4.59460e+02  1.57052e+03  8.71660e+02  1.07124e+03  1.55840e+03\n",
      " -5.21710e+02  1.42100e+01  1.23778e+03  1.46461e+03  2.32000e+00\n",
      "  2.63816e+03  4.94631e+03  8.16520e+02  1.68291e+03  9.40480e+02\n",
      " -7.49300e+02  8.14730e+02  6.23890e+02  1.33925e+03  5.19500e+02\n",
      "  1.48573e+03  2.25470e+02  8.04510e+02  1.20675e+03  2.22912e+03\n",
      "  1.12722e+03  8.34170e+02  5.13450e+02  9.94710e+02  1.36975e+03\n",
      "  9.60700e+01  4.99910e+02  7.94750e+02  1.22200e+03  6.38050e+02\n",
      "  4.53610e+02  1.31978e+03  1.31738e+03  1.31010e+02  7.75890e+02\n",
      "  1.39562e+03  3.34400e+01 -3.40000e+02  1.29752e+03  7.76630e+02\n",
      "  3.56060e+02  2.05214e+03  1.30261e+03  1.43741e+03  1.02067e+03\n",
      "  1.42661e+03  1.13090e+02  6.94250e+02  1.33196e+03 -1.13799e+03\n",
      "  1.70900e+01  1.41615e+03  6.76420e+02  4.62920e+02 -6.54320e+02\n",
      "  1.79360e+02  2.66880e+02 -2.79550e+02  1.39520e+03  2.29661e+03\n",
      "  9.15850e+02  7.06070e+02  5.75920e+02  1.13245e+03  1.31186e+03\n",
      "  2.42810e+02  6.91730e+02 -9.89530e+02  1.43532e+03  5.16460e+02\n",
      "  1.57683e+03  7.99820e+02  3.06870e+02  1.14552e+03  1.80238e+03\n",
      "  2.34187e+03  1.47493e+03  1.08121e+03  1.02890e+03  1.31220e+03\n",
      "  2.70822e+03  2.38901e+03  9.61340e+02  5.61290e+02 -1.21256e+03\n",
      "  1.92097e+03  1.25905e+03  1.03267e+03  7.68370e+02  2.88780e+03\n",
      " -3.54100e+01  1.68597e+03  8.93710e+02  9.08990e+02  2.17458e+03\n",
      "  7.03940e+02  1.52500e+03 -9.38780e+02  4.07340e+02  5.37230e+02\n",
      "  1.05718e+03  9.95470e+02  4.49500e+01  1.90832e+03  1.89696e+03\n",
      " -4.42660e+02  1.34567e+03  3.91250e+02  2.27840e+02  1.50357e+03\n",
      "  3.79480e+02 -1.34127e+03  9.50120e+02  2.12107e+03 -2.25700e+01\n",
      " -1.41239e+03]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "\n",
    "# Shuffle the training data\n",
    "train_permutation = np.random.permutation(len(X_train))\n",
    "X_train = X_train[train_permutation]\n",
    "y_train = y_train[train_permutation]\n",
    "\n",
    "# Shuffle the testing data\n",
    "test_permutation = np.random.permutation(len(X_test))\n",
    "X_test = X_test[test_permutation]\n",
    "y_test = y_test[test_permutation]\n",
    "print(\"X_train:\\n\", X_train)\n",
    "print(\"y_train:\\n\", y_train)\n",
    "print(\"X_test:\\n\", X_test)\n",
    "print(\"y_test:\\n\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1343, 23), (1343,), (576, 23), (576,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized X_train shape: (1343, 23)\n",
      "Normalized X_test shape: (576, 23)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() # Good for XGBoost and Neural Networks\n",
    "\n",
    "# Fit the scaler on the training data and transform both train and test sets\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "# Print normalized shapes\n",
    "print(\"Normalized X_train shape:\", X_train_normalized.shape)\n",
    "print(\"Normalized X_test shape:\", X_test_normalized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized y_train shape: (1343, 1)\n",
      "Normalized y_test shape: (576, 1)\n"
     ]
    }
   ],
   "source": [
    "# Normalize the target variable for regression\n",
    "y_scaler = StandardScaler()  \n",
    "y_train_normalized = y_scaler.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test_normalized = y_scaler.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "print(\"Normalized y_train shape:\", y_train_normalized.shape)\n",
    "print(\"Normalized y_test shape:\", y_test_normalized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.88\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor(n_estimators=100, max_depth=6, learning_rate=0.3, random_state=42)\n",
    "\n",
    "model.fit(X_train_normalized, y_train_normalized)\n",
    "\n",
    "y_pred = model.predict(X_test_normalized)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test_normalized, y_pred)\n",
    "print(f\"MSE: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost + PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95)  # Retain 95% of variance\n",
    "X_train_pca = pca.fit_transform(X_train_normalized)\n",
    "X_test_pca = pca.transform(X_test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.65\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor(n_estimators=100, max_depth=6, learning_rate=0.3, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train_pca, y_train_normalized)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_pca)\n",
    "\n",
    "# Evaluate \n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test_normalized, y_pred)\n",
    "print(f\"MSE: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "X_train_normalized_tensor = torch.tensor(X_train_normalized, dtype=torch.float32)\n",
    "X_test_normalized_tensor = torch.tensor(X_test_normalized, dtype=torch.float32)\n",
    "y_train_normalized_tensor = torch.tensor(y_train_normalized, dtype=torch.float32)\n",
    "y_test_normalized_tensor = torch.tensor(y_test_normalized, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Train Loss: 0.9876, Validation Loss: 0.5320\n",
      "Epoch [20/100], Train Loss: 0.9799, Validation Loss: 0.5242\n",
      "Epoch [30/100], Train Loss: 0.9736, Validation Loss: 0.5182\n",
      "Epoch [40/100], Train Loss: 0.9679, Validation Loss: 0.5131\n",
      "Epoch [50/100], Train Loss: 0.9623, Validation Loss: 0.5086\n",
      "Epoch [60/100], Train Loss: 0.9568, Validation Loss: 0.5044\n",
      "Epoch [70/100], Train Loss: 0.9514, Validation Loss: 0.5003\n",
      "Epoch [80/100], Train Loss: 0.9458, Validation Loss: 0.4963\n",
      "Epoch [90/100], Train Loss: 0.9403, Validation Loss: 0.4924\n",
      "Epoch [100/100], Train Loss: 0.9346, Validation Loss: 0.4886\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(23, 64)  # Input layer with 23 features\n",
    "        self.layer2 = nn.Linear(64, 32)  \n",
    "        self.layer3 = nn.Linear(32, 1)   \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))   \n",
    "        x = torch.relu(self.layer2(x)) \n",
    "        x = self.layer3(x)               # No activation in the output layer for regression\n",
    "        return x\n",
    "\n",
    "model = SimpleNN()\n",
    "\n",
    "criterion = nn.MSELoss()  # MSE for regression\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_normalized_tensor)    \n",
    "    loss = criterion(outputs, y_train_normalized_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_test_normalized_tensor)\n",
    "        val_loss = criterion(val_outputs, y_test_normalized_tensor)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}, Validation Loss: {val_loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
